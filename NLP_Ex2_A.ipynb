{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w2vMQfSvZm-W",
        "outputId": "db3574fc-1f81-4e01-d276-1a5d58fef557"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: hazm in /usr/local/lib/python3.7/dist-packages (0.7.0)\n",
            "Requirement already satisfied: libwapiti>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from hazm) (0.2.1)\n",
            "Requirement already satisfied: nltk==3.3 in /usr/local/lib/python3.7/dist-packages (from hazm) (3.3)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from nltk==3.3->hazm) (1.15.0)\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import re\n",
        "!pip install hazm\n",
        "from hazm import word_tokenize"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.preprocessing.text import Tokenizer, text_to_word_sequence\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.layers import Dense, Dropout, Embedding, LSTM, Bidirectional, Input, TimeDistributed, Flatten\n",
        "from keras import Model\n",
        "from sklearn.metrics import classification_report,confusion_matrix\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "s-FptAOmtRnT"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-zRK2jrLexTO",
        "outputId": "7a5e024f-2bea-4a85-f45f-86664984f800"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/gdown/cli.py:131: FutureWarning: Option `--id` was deprecated in version 4.3.1 and will be removed in 5.0. You don't need to pass it anymore to use a file ID.\n",
            "  category=FutureWarning,\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1D3yt99D0GcCRCbdKbUQGxbqjkeh91hTg\n",
            "To: /content/hamshahri.rar\n",
            "100% 873M/873M [00:03<00:00, 274MB/s]\n"
          ]
        }
      ],
      "source": [
        "!gdown --id 1D3yt99D0GcCRCbdKbUQGxbqjkeh91hTg"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "TDlFVkDDkrIR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1d670a2b-4fff-47c4-cc2a-364de48393c4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "UNRAR 5.50 freeware      Copyright (c) 1993-2017 Alexander Roshal\n",
            "\n",
            "\n",
            "Extracting from /content/hamshahri.rar\n",
            "\n",
            "\n",
            "Would you like to replace the existing file /content/hamshahriold/CLEF/images/ar.JPG\n",
            "  1114 bytes, modified on 2008-05-04 12:51\n",
            "with a new one\n",
            "  1114 bytes, modified on 2008-05-04 12:51\n",
            "\n",
            "[Y]es, [N]o, [A]ll, n[E]ver, [R]ename, [Q]uit \n",
            "User break\n",
            "\n",
            "User break\n"
          ]
        }
      ],
      "source": [
        "!unrar x /content/hamshahri.rar -d /content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CEk9IJ7LV-fv",
        "outputId": "72c0bed2-b9ff-4ffd-f154-d3753af2f645"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  /content/hamshahriold/Corpus/Hamshahri-Corpus.zip\n",
            "replace /content/DataSet/Hamshahri-Corpus.txt? [y]es, [n]o, [A]ll, [N]one, [r]ename: A\n",
            "  inflating: /content/DataSet/Hamshahri-Corpus.txt  \n",
            "Archive:  /content/hamshahriold/Corpus/PersianStopWords.zip\n",
            "replace /content/StopWords/PersianStopWords.txt? [y]es, [n]o, [A]ll, [N]one, [r]ename: A\n",
            "  inflating: /content/StopWords/PersianStopWords.txt  \n"
          ]
        }
      ],
      "source": [
        "!unzip /content/hamshahriold/Corpus/Hamshahri-Corpus.zip -d /content/DataSet\n",
        "!unzip /content/hamshahriold/Corpus/PersianStopWords.zip -d /content/StopWords"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open('/content/DataSet/Hamshahri-Corpus.txt') as f:\n",
        "    dataset = f.readlines ()\n",
        "    \n",
        "for i in range (10) :\n",
        "  print (dataset[i])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D7uE2VmT9TZJ",
        "outputId": "f93d18e7-ccca-4cd9-f01c-058dea366919"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            ".DID\t1S1\n",
            "\n",
            ".Date\t75\\04\\02\n",
            "\n",
            ".Cat\tadabh\n",
            "\n",
            "جاودانگي در زندگي گروهي از طريق هنر \n",
            "\n",
            "نگاهي به نمايشگاه آثار هنري احمد طباطبايي \n",
            "\n",
            "موضوع آثار طباطبايي مورچگان هستند ولي در باطن چنين ظاهري، اين \n",
            "\n",
            "انسانهاهستند كه در هيبتي حشره گونه در تابلوهاي نقاشي نمايشگر \n",
            "\n",
            "گوشه هايي از زندگي خود هستند. \n",
            "\n",
            "مورچه اي را ديده ايم كه بار سنگين خودرا به دوش مي كشد و در بين راه \n",
            "\n",
            "خسته مي شود يا در نتيجه پيش آمدن يك حادثه اتفاقي بار از دستش رها \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open('/content/StopWords/PersianStopWords.txt') as f:\n",
        "    stopwords = f.readlines ()\n",
        "\n",
        "stopwords = [ x.replace ('\\n', '').replace ('\\ufeff', '') for x in stopwords ]\n",
        "print (stopwords)\n",
        "print (len(stopwords))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jNQrvoKsei0O",
        "outputId": "199b0cc2-58db-4f16-819a-20c00e158ec8"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['ـ', '-', '!', '\"', '#', '(', ')', '*', '.', '...', '....', '/', ':', '[', ']', '،', '؛', '؟', '«', '»', '…', 'آاو و و و', 'آخ', 'آخر', 'آخرها', 'آخه', 'آدمهاست', 'آرام', 'آرام آرام', 'آره', 'آزادانه', 'آسان', 'آسيب پذيرند', 'آشكارا', 'آشنايند', 'آمرانه', 'آن', 'آن گاه', 'آن ها', 'آنان', 'آناني', 'آنجا', 'آنچنان', 'آنچنان كه', 'آنچه', 'آنرا', 'آنقدر', 'آنگاه', 'آنها', 'آنهاست', 'آهان', 'آهاي', 'آوه', 'آيا', 'ا', 'اتفاقا', 'اجراست', 'احتمالا', 'احياناً', 'اخيراً', 'از', 'از آن پس', 'از جمله', 'ازاين رو', 'ازش', 'اساساً', 'است', 'اسلامي اند', 'اش', 'اشتباها', 'اصلا', 'اصلاً', 'اصولا', 'اصولاً', 'اغلب', 'افسوس', 'اقل', 'اقليت', 'اكثر', 'اكثرا', 'اكثراً', 'اكثريت', 'اكنون', 'اگر', 'اگر چه', 'اگرچه', 'اگه', 'الا', 'الان', 'البته', 'الهي', 'الي', 'اما', 'امروز', 'امروزه', 'امسال', 'امشب', 'اميدوارم', 'اميدوارند', 'اميدواريم', 'ان شاأالله', 'اند', 'اندكي', 'انگار', 'او', 'اوست', 'اولا', 'اولاً', 'اون', 'اي', 'ايشان', 'اين', 'اين جوري', 'اين قدر', 'اين گونه', 'اينان', 'اينجا', 'اينجاست', 'اينكه', 'اينها', 'اينهاست', 'اينو', 'ب ', 'با', 'بااين حال', 'بااين وجود', 'بار', 'بارها', 'باز', 'باز هم', 'بازي كنان', 'بازيگوشانه', 'بالا', 'بالاخره', 'بالاخص', 'بالاست', 'بالاي', 'بالعكس', 'باوجودي كه', 'باورند', 'بايد', 'بپا', 'بتدريج', 'بجز', 'بخشه', 'بخصوص', 'بخوبي', 'بدان', 'بدانجا', 'بدانها', 'بدون', 'بدين', 'بدين ترتيب', 'بدينجا', 'بر', 'برآنند', 'برا', 'براساس', 'براي', 'برايت', 'برايش', 'برايشان', 'برايم', 'برايمان', 'برخوردارند', 'برخي', 'برعكس', 'برنامه سازهاست', 'بروشني', 'بس', 'بسا', 'بسادگي', 'بسختي', 'بسوي', 'بسي', 'بسيار', 'بسياري', 'بشدت', 'بطوري كه', 'بعد', 'بعد از اين كه', 'بعدا', 'بعداً', 'بعدازظهر', 'بعدها', 'بعضي', 'بعضي شان', 'بعضي ها', 'بعضيهايشان', 'بعلاوه', 'بعيد', 'بفهمي نفهمي', 'بكار', 'بلافاصله', 'بلكه', 'بله', 'بنابراين', 'به', 'به آساني', 'به تازگي', 'به تدريج', 'به تمامي', 'به جاي', 'به جز', 'به خوبي', 'به درشتي', 'به دلخواه', 'به راستي', 'به رغم', 'به روشني', 'به زودي', 'به سادگي', 'به سرعت', 'به شان', 'به شدت', 'به طور كلي', 'به طوري كه', 'به علاوه', 'به قدري', 'به كرات', 'به گرمي', 'به مراتب', 'به ناچار', 'به هرحال', 'به هيچ وجه', 'به وضوح', 'به ويژه', 'بهت', 'بهتر', 'بهش', 'بود', 'بويژه', 'بي', 'بي آنكه', 'بي اطلاعند', 'بي ترديد', 'بي تفاوتند', 'بي نيازمندانه', 'بي هدف', 'بيرون', 'بيشتر', 'بيگمان', 'بين', 'پ', 'پارسال', 'پارسايانه', 'پاره اي', 'پايين ترند', 'پدرانه', 'پديده هاست', 'پرسان', 'پروردگارا', 'پريروز', 'پس', 'پس از', 'پس فردا', 'پشت', 'پشتوانه اند', 'پشيموني', 'پهن شده', 'پي', 'پي درپي', 'پيداست', 'پيرامون', 'پيش', 'پيوسته', 'ت', 'تا', 'تازه', 'تاكنون', 'تحت', 'تحريم هاست', 'تر', 'تصريحاً', 'تعدادي', 'تعمدا', 'تقريبا', 'تقريباً', 'تك تك', 'تلويحاً', 'تمام', 'تمام قد', 'تماما', 'تمامشان', 'تمامي', 'تند تند', 'تنها', 'تو', 'توؤماً', 'توسط', 'توي', 'ث', 'ثالثاً', 'ثانياً', 'ج', 'جداً', 'جداگانه', 'جديدا', 'جرمزاست', 'جز', 'جلو', 'جلوي', 'جمع اند', 'جمعي', 'جنابعالي', 'جنس اند', 'جهت', 'جور', 'چ', 'چاپلوسانه', 'چت', 'چته', 'چرا', 'چرا كه', 'چشم بسته', 'چطور', 'چقدر', 'چكار', 'چگونه', 'چنان', 'چنانچه', 'چند', 'چند روزه', 'چندان', 'چنده', 'چندين', 'چنين', 'چه', 'چه بسا', 'چه طور', 'چو', 'چون', 'چي', 'چيزهاست', 'چيزيست', 'چيست', 'چيه', 'ح', 'حاشيه اي', 'حاضرم', 'حاكيست', 'حال', 'حتما', 'حتماً', 'حتي', 'حداقل', 'حداكثر', 'حدود', 'حسابگرانه', 'حضرتعالي', 'حقيرانه', 'حكماً', 'حول', 'خ', 'خالصانه', 'خب', 'خداحافظ', 'خداست', 'خسته اي', 'خصوصاً', 'خواسته', 'خواهد', 'خوب', 'خود', 'خود به خود', 'خودبه خودي', 'خودت', 'خودتان', 'خودتو', 'خودش', 'خودشان', 'خودم', 'خودمان', 'خودمو', 'خوش', 'خوشبختانه', 'خويش', 'خويشتنم', 'خير', 'خيره', 'خيلي', 'د', 'دا', 'داام', 'دااما', 'داخل', 'داراست', 'دارد', 'دامم', 'در', 'در باره', 'در بارهٌ', 'در ثاني', 'در كل', 'در كنار', 'در مجموع', 'در نهايت', 'در واقع', 'دراين ميان', 'درباره', 'درحالي كه', 'درحاليكه', 'درست', 'درست و حسابي', 'درسته', 'درصورتي كه', 'درعين حال', 'درواقع', 'دريغ', 'دريغا', 'دسته دسته', 'دشمنيم', 'دقيقا', 'دم', 'دهد', 'دو روزه', 'دوباره', 'دير', 'ديرت', 'ديرم', 'ديروز', 'ديشب', 'ديگر', 'ديگران', 'ديگري', 'ديگه', 'ديوانه اي', 'ديوي', 'ذ', 'ذاتاً', 'ر', 'را', 'راجع به', 'راحت', 'راست', 'راستي', 'رشته', 'رفتارهاست', 'رنجند', 'رهگشاست', 'رو', 'رواست', 'روبروست', 'روز به روز', 'روزانه', 'روزه اي', 'روزه ايم', 'روزه ست', 'روزه م', 'روش', 'روي', 'رويش', 'ز', 'زشتكارانند', 'زنند', 'زهي', 'زودتر', 'زياد', 'زياده', 'زير', 'زيرا', 'زيرچشمي', 'ژ', 'س', 'ساده اند', 'ساكنند', 'سالانه', 'سالته', 'سالم تر', 'سالهاست', 'سپس', 'سخت', 'سخته', 'سر', 'سراپا', 'سراسر', 'سرانجام', 'سري', 'سريع', 'سريعاً', 'سه باره', 'سهواً', 'سياه چاله هاست', 'سيخ', 'ش', 'شاهدند', 'شاهديم', 'شايد', 'شبهاست', 'شخصا', 'شخصاً', 'شد', 'شدن', 'شده', 'شديدا', 'شديداً', 'شما', 'شماري', 'شماست', 'شمايند', 'شود', 'شوراست', 'شوقم', 'شيرين', 'شيرينه', 'شيك', 'ص', 'صددرصد', 'صرفا', 'صرفاً', 'صريحاً', 'صندوق هاست', 'ض', 'ضمناً', 'ط', 'طبعاً', 'طبيعتا', 'طلبكارانه', 'طي', 'ظ', 'ظاهرا', 'ظاهراً', 'ع', 'عاجزانه', 'عاقبت', 'عبارتند', 'عجب', 'عجولانه', 'عرفاني', 'عقب', 'علاوه بر', 'علاوه بر آن', 'علاوه برآن', 'علناً', 'علي الظاهر', 'علي رغم', 'عليه', 'عمدا', 'عمداً', 'عمدتا', 'عمدتاً', 'عمده', 'عملا', 'عملاً', 'عملي اند', 'عموم', 'عموما', 'عموماً', 'عنقريب', 'عيناً', 'غ', 'غالبا', 'غزالان', 'غيرقانوني', 'ف', 'فاقد', 'فبها', 'فر', 'فردا', 'فعلاً', 'فقط', 'فلان', 'فلذا', 'ق', 'قاالند', 'قاطبه', 'قاطعانه', 'قاعدتاً', 'قانوناً', 'قبلا', 'قبلاً', 'قبلند', 'قدر', 'قدري', 'قضاياست', 'قطعا', 'قطعاً', 'ك', 'كارند', 'كاش', 'كاشكي', 'كاملا', 'كاملاً', 'كجا', 'كجاست', 'كدام', 'كرده', 'كلا', 'كلي', 'كليشه هاست', 'كليه', 'كم كم', 'كما\\x7fاينكه', 'كمتر', 'كمتره', 'كمي', 'كنار', 'كنارش', 'كنايه اي', 'كند', 'كنم', 'كنند', 'كه', 'كي', 'گ', 'گاه', 'گاهي', 'گرچه', 'گرفتارند', 'گونه', 'گويي', 'ل', 'لااقل', 'لاجرم', 'لب', 'لذا', 'لزوماً', 'لطفا', 'ليكن', 'م', 'ما', 'مادامي', 'ماست', 'مامان مامان گويان', 'مانند', 'متؤسفانه', 'متاسفانه', 'متفاوتند', 'مثل', 'مثلا', 'مجبورند', 'مجدداً', 'مجموعاً', 'محتاجند', 'محكم', 'محكم تر', 'مخالفند', 'مخصوصاً', 'مدام', 'مدتهاست', 'مذهبي اند', 'مرا', 'مرتب', 'مردانه', 'مردم اند', 'مستحضريد', 'مستقيما', 'مستند', 'مشت', 'مشتركاً', 'مشغولند', 'مطمانا', 'مطمانم', 'مع الاسف', 'مع ذلك', 'معتقدم', 'معتقدند', 'معتقديم', 'معدود', 'معذوريم', 'معلومه', 'معمولا', 'معمولاً', 'معمولي', 'مغرضانه', 'مفيدند', 'مقدار', 'مقصرند', 'مقصري', 'مكرر', 'مكرراً', 'مگر', 'مگر آن كه', 'مگر اين كه', 'مميزيهاست', 'من', 'منتهي', 'منطقي', 'مني', 'مواجهند', 'موجودند', 'مورد', 'مي', 'ميان', 'ميزان', 'ن', 'نااميد', 'ناخواسته', 'ناراضي اند', 'ناگزير', 'ناگهان', 'نبش', 'نخست', 'نخودي', 'ندارد', 'نزد', 'نزديك', 'نظير', 'نفرند', 'نمي', 'نه', 'نه تنها', 'نهايتا', 'نهايتاً', 'نوع', 'نوعاً', 'نيازمندند', 'نيز', 'نيمي', 'ه', 'ها', 'هاي', 'هايي', 'هر', 'هر از گاهي', 'هر چند', 'هر چند كه', 'هر چه', 'هرچند', 'هرچه', 'هركس', 'هرگاه', 'هرگز', 'هستند', 'هق هق كنان', 'هم', 'هم اكنون', 'هم اينك', 'همان', 'همان طور كه', 'همان گونه كه', 'همانند', 'همانها', 'همچنان', 'همچنان كه', 'همچنين', 'همچون', 'همچين', 'همديگر', 'همزمان', 'همگان', 'همگي', 'همه', 'همهٌ', 'همه اش', 'همه روزه', 'همه ساله', 'همه شان', 'همواره', 'هميشه', 'همين', 'همين كه', 'هنگامي كه', 'هنوز', 'هوي', 'هي', 'هيچ', 'هيچ گاه', 'هيچكدام', 'هيچكس', 'هيچگاه', 'هيچگونه', 'هيچي', 'و', 'و لا غير', 'وابسته اند', 'واقعا', 'واقعاً', 'واقعي', 'واقفند', 'واي', 'وجود', 'وحشت زده', 'وقتي', 'وقتي كه', 'وگرنه', 'ولي', 'وي', 'ويا', 'ي', 'يا', 'يابد', 'يارب', 'يعني', 'يقيناً', 'يك', 'يك جوري', 'يك كم', 'يك كمي', 'يكديگر', 'يكريز', 'يكسال', 'يكي', 'يواش يواش', 'ک', 'ی']\n",
            "796\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Dataset = []\n",
        "Cats = []\n",
        "temp = \"\"\n",
        "\n",
        "for x in dataset :\n",
        "\n",
        "  match1 = re.findall(\"\\.DID\", x)\n",
        "  match2 = re.findall(\"\\.Date\", x)\n",
        "  match3 = re.findall(\"\\.Cat\", x)\n",
        "\n",
        "  if match1 or match2 :\n",
        "    continue\n",
        "  elif match3 : \n",
        "    x = x.replace ('.Cat', '').replace ('\\t', '').replace ('\\n', '')\n",
        "    Cats.append (x)\n",
        "    if temp != \"\" :\n",
        "      Dataset.append (temp)\n",
        "    temp = \"\"\n",
        "  else :\n",
        "    x = x.replace ('\\n', '')\n",
        "    temp += x"
      ],
      "metadata": {
        "id": "R4JyjE_ZlFLe"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Corpus = []\n",
        "\n",
        "for index, x in enumerate (Dataset) :\n",
        "  Corpus.append ([x, Cats [index]])"
      ],
      "metadata": {
        "id": "8RMAa7kMS6fM"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.DataFrame(Corpus, columns=['text', 'category'])"
      ],
      "metadata": {
        "id": "RQTPWco2S3Ff"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.to_csv(\"dataset.csv\")"
      ],
      "metadata": {
        "id": "3M_NXUq9Zj39"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for index, txt in enumerate(df[\"text\"]):\n",
        "  word_tokenized = word_tokenize(txt)\n",
        "  Clean_Text = \"\"\n",
        "  for word in word_tokenized :\n",
        "    if word not in stopwords :\n",
        "      Clean_Text += word + \" \"\n",
        "      \n",
        "  df.loc[index].at['text'] = Clean_Text"
      ],
      "metadata": {
        "id": "eqg1AYmGaxHD"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G0dtJNhhdncU",
        "outputId": "d76d0698-051a-4027-d606-b94df46d8c2d"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.to_csv(\"/content/gdrive/MyDrive/save.csv\")"
      ],
      "metadata": {
        "id": "ZPAfbsCPczQr"
      },
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv (\"/content/gdrive/MyDrive/save.csv\")"
      ],
      "metadata": {
        "id": "KQ34ARD_dTf9"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Unique_Cats = []\n",
        "\n",
        "for cat in df ['category'] :\n",
        "  if cat not in Unique_Cats :\n",
        "      Unique_Cats.append (cat)\n",
        "\n",
        "len (Unique_Cats)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pZNr_uSucB30",
        "outputId": "28b7cce2-c803-4478-873a-b729ff99d54f"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "105"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Cat_IDs = {word: i for i, word in enumerate(Unique_Cats)}"
      ],
      "metadata": {
        "id": "SI7O1pYXfaBi"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ID_To_Cat = {idx:l for idx, l in enumerate(Unique_Cats)}"
      ],
      "metadata": {
        "id": "Of7xGnbu9BNP"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['category_id'] = df['category'].apply(lambda t: Cat_IDs[t])\n"
      ],
      "metadata": {
        "id": "Uw1tScq8fPkh"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = df.dropna(subset=['text'])\n",
        "df = df.reset_index(drop=True)"
      ],
      "metadata": {
        "id": "JBMh3mzqy42K"
      },
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for x in df ['text'] :\n",
        "  if type (x) == float :\n",
        "    print (x)"
      ],
      "metadata": {
        "id": "c0WMFGuGyhmb"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "t = Tokenizer()\n",
        "t.fit_on_texts(df ['text'].tolist())\n",
        "Word_To_ID = t.word_index\n",
        "ID_To_Word = {v:k for k, v in Word_To_ID.items()}\n",
        "wids = [[Word_To_ID[w] for w in text_to_word_sequence(doc)] for doc in df['text'].tolist()]\n",
        "vocab_size = len(t.word_index) + 1\n",
        "max_length = 200\n",
        "X = pad_sequences(wids, maxlen=max_length, padding='post')\n",
        "y = df['category_id'].tolist()"
      ],
      "metadata": {
        "id": "YiBNKbF3ftWw"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print (df['text'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ExQNSUqd0UFz",
        "outputId": "d6cdee67-afec-4aca-b10d-73b895456405"
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0         جاودانگي زندگي گروهي طريق هنر نگاهي نمايشگاه آ...\n",
            "1         رويدادهاي هنري جهان نمايشگاه هنر خدمت ديكتاتور...\n",
            "2         برديوار نگارخانه گالري گلستان نمايشگاه طرح ساخ...\n",
            "3         بازي جدي بگيريم مطالعه مقدماتي نقش بازي زندگي ...\n",
            "4         تخته سياه غباري سترده اشاره; رغم گسترش توسعه ر...\n",
            "                                ...                        \n",
            "165197    گره كور كشتي شودگروه ورزشي حضور رسمي محمدرضا ط...\n",
            "165198    نماينده فدراسيون جهاني واليبال ايران نظر شايست...\n",
            "165199    شكست نامداران تكواندودر پيكارهاي برتر ليگ گروه...\n",
            "165200    ورزشگاه بزرگ دانشگاه آزاد تهران ساخته گروه ورز...\n",
            "165201    رئيس فدراسيون پزشكي انتخاب گروه ورزشي مجمع عمو...\n",
            "Name: text, Length: 165202, dtype: object\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# main model\n",
        "input = Input(shape=(max_length,))\n",
        "model = Embedding(vocab_size, 128 ,input_length=max_length)(input)\n",
        "model =  Bidirectional (LSTM (100,return_sequences=True,dropout=0.50),merge_mode='concat')(model)\n",
        "model = TimeDistributed(Dense(100,activation='relu'))(model)\n",
        "model = Flatten()(model)\n",
        "model = Dense(100,activation='relu')(model)\n",
        "output = Dense(len (Unique_Cats), activation='softmax')(model)\n",
        "model = Model(input, output)\n",
        "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "5aowaso1tTBR"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "--peEYMq2ug6",
        "outputId": "60ba63f8-7c64-4ebe-bc6a-1e962c674f8e"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_5\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_6 (InputLayer)        [(None, 200)]             0         \n",
            "                                                                 \n",
            " embedding_5 (Embedding)     (None, 200, 128)          66822656  \n",
            "                                                                 \n",
            " bidirectional_6 (Bidirectio  (None, 200, 200)         183200    \n",
            " nal)                                                            \n",
            "                                                                 \n",
            " time_distributed_1 (TimeDis  (None, 200, 100)         20100     \n",
            " tributed)                                                       \n",
            "                                                                 \n",
            " flatten_1 (Flatten)         (None, 20000)             0         \n",
            "                                                                 \n",
            " dense_8 (Dense)             (None, 100)               2000100   \n",
            "                                                                 \n",
            " dense_9 (Dense)             (None, 105)               10605     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 69,036,661\n",
            "Trainable params: 69,036,661\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(X.shape)\n",
        "print (len(y))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pjwjwUpSz_WU",
        "outputId": "828ccbc3-797b-4bc8-b8b6-97f379ac7e19"
      },
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(165202, 400)\n",
            "165202\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(X ,np.array (y) , epochs = 10, verbose = 1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 528
        },
        "id": "1gwt56St1Fmq",
        "outputId": "d8aae83f-be94-480c-b769-5eff4cc4abf2"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "5163/5163 [==============================] - 287s 56ms/step - loss: 0.9056 - accuracy: 0.7613\n",
            "Epoch 2/10\n",
            "5163/5163 [==============================] - 292s 57ms/step - loss: 0.5630 - accuracy: 0.8356\n",
            "Epoch 3/10\n",
            "5163/5163 [==============================] - 303s 59ms/step - loss: 0.3521 - accuracy: 0.8929\n",
            "Epoch 4/10\n",
            "5163/5163 [==============================] - 308s 60ms/step - loss: 0.2192 - accuracy: 0.9319\n",
            "Epoch 5/10\n",
            " 101/5163 [..............................] - ETA: 4:39 - loss: 0.1174 - accuracy: 0.9663"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-25-f2bcddea91e2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m \u001b[0;34m,\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1382\u001b[0m                 _r=1):\n\u001b[1;32m   1383\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1384\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1385\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1386\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    913\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    914\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 915\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    916\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    917\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    945\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    946\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 947\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    948\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    949\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2955\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   2956\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 2957\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   2958\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2959\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1852\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1853\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1854\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1855\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1856\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    502\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    503\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 504\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    505\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    506\u001b[0m           outputs = execute.execute_with_cancellation(\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 55\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     56\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save_weights(\"/content/gdrive/MyDrive/MyModel.h5\")"
      ],
      "metadata": {
        "id": "AY-OCMDSsGtb"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.load_weights(\"/content/gdrive/MyDrive/MyModel.h5\")"
      ],
      "metadata": {
        "id": "_lF9FH-W98wR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess(texts):\n",
        "  results = []\n",
        "  stop_words_list = []\n",
        "  with open('/content/StopWords/PersianStopWords.txt', \"rb\") as file:\n",
        "    for line in file:\n",
        "      stop_words_list.append(line.decode(\"UTF-8\").replace('\\r\\n', \"\"))\n",
        "  for txt in texts:\n",
        "    word_tokenized = word_tokenize(txt)\n",
        "    cps = \"\"\n",
        "    for word in word_tokenized:\n",
        "      if word not in stop_words_list:\n",
        "        cps += word + \" \"\n",
        "    results.append(cps)\n",
        "  return(results)"
      ],
      "metadata": {
        "id": "Iwl0hRMf8QUB"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def prediction(texts):\n",
        "  result = []\n",
        "  cleaned_texts = preprocess(texts)\n",
        "  for cleaned_text in cleaned_texts:\n",
        "    text_to_sequences = t.texts_to_sequences([cleaned_text])\n",
        "    pad_text_to_sequences = pad_sequences(text_to_sequences, maxlen=max_length)\n",
        "    category = model.predict([pad_text_to_sequences])[0]\n",
        "\n",
        "    category_index = np.where(category == max(category))\n",
        "    result.append(ID_To_Cat [category_index[0][0]])\n",
        "  return result"
      ],
      "metadata": {
        "id": "FQU8JHCy71E6"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "List = ['میرهاشم موسوی در پاسخ به گلایهها و انتقادات بازنشستگان غیرحداقلیبگیر از نحوه افزایش حقوقها در سال جاری اظهار کرد: آنچه ما باید بر اساس قانون به عنوان سازمان تامین اجتماعی انجام میدادیم همان را انجام دادیم و همان مسیری بوده که تا کنون طی کردهایم.  وی افزود: در ماده ۹۶ قانون تامین اجتماعی قید شده است که میزان افزایش حقوق غیرحداقلیبگیران باید بر اساس هزینههای زندگی تعیین و سپس در هیئت وزیران مصوب شود و به اجرا دربیاید. در ماده ۱۱۱ قانون تامین اجتماعی هم آمده است که میزان افزایش حقوق حداقلیبگیران نباید از حداقل دستمزد کارگران که در شورای عالی کار مصوب شده، کمتر باشد.  مدیرعامل سازمان تامین اجتماعی با بیان اینکه ما بر اساس ماده ۹۶ و ۱۱۱ قانون تامین اجتماعی مسیر افزایش حقوقها را طی کرده و مصوبه هیئت امنای تامین اجتماعی را به دولت ارسال کردیم گفت: این تصمیم، تصمیمِ بخشی و سازمانی ما بود و هیئت امنا همین را پذیرفت و به هیئت دولت ارسال کرد اما اقتضائاتی که در هیئت دولت مطرح است، به علاوه نگاه بخشی ما در تامین اجتماعی است و طبیعتا قانونگذار هم این اختیار را بر اساس ماده ۹۶ به هیئت وزیران داده است که این ملاحظات و اقتضائات را درنظر بگیرد.       موسوی ادامه داد: آن پیشنهادی که ما ارائه دادیم، قانون است و اینکه باید اقتضائات در دولت دیده شود هم قانون است؛ هر دو قانون هستند و نمیتوانیم یک سوی قانون را ببینیم و آن سوی قانون را نادیده بگیریم. خب تصمیم نهایی در هیئت دولت با توجه به ملاحظاتی که برای مابقی صندوقها وجود داشت و همچنین دیگر موارد فرابخشی در اقتصاد کلان و بخشهای مختلف، اتخاذ شد. آنجا هیئت وزیران است و همه باید نظر بدهند و تصمیم نهایی اخذ شود.  وی افزود: البته در جلسات کارشناسی مختلفی که ما حضور داشتیم، نظرات خود را ارائه کرده بودیم و تبیین کارشناسی خودمان را داشتیم. در نهایت  تصمیمی که گرفته شد این بود که برای حداقلی بگیران ۵۷.۴ درصد افزایش داشته باشیم. برای سایر سطوح درآمدی نیز دو سطح قائل شدند، نخست حقوق بگیران زیر ۱۰ میلیون تومان که مشمول افزایش ۱۰ درصدی به علاوه ۶۵۰ هزار تومان مبلغ ثابت شدند و دوم حقوقبگیران بالای ۱۰ میلیون تومان که حقوقشان ۱۰ درصد افزایش پیدا کرد.  مدیرعامل سازمان تامین اجتماعی با اشاره به اینکه برای بخشی از \"سایر سطوح\" که شاید چیزی حدود به ۹۰۰ هزار نفر بازنشسته را شامل میشود، این تصمیم برای افزایش حقوق، محل سوال شد و معترض بودند اظهار کرد: این موضوع در دولت در حال بررسی بود که هیئت تطبیق قوانین مجلس هم ورود پیدا کرد و نظرات خودشان را اعلام کردند.  موسوی درباره نحوه پرداختهای جبرانی به این گروه از بازنشستگان که پیش از این از سوی سرپرست وزارت رفاه وعده داده و در برخی رسانهها منتشر شده است نیز توضیح داد و گفت: اکنون این موضوع در دولت در حال بررسی است. ما نمیتوانیم بگوییم که با چه الگویی میخواهیم این را جبران کنیم. منتظر تصمیم نهایی هستیم که آنچه باید بر اساس قانون انجام دهیم را انجام دهیم و این آمادگی در تامین اجتماعی وجود دارد که وفق قانون هر تصمیمی گرفته شد را عمل کرده و اقدامی که باید برای این عزیزان در پرداخت مستمریها اتفاق بیفتد را انجام دهد.']\n",
        "prediction (List)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D5i7Tfgy9gE6",
        "outputId": "19c229ac-22b3-47e5-9a6d-7c3e9bfb3dd4"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['aeqts']"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "NLP_Ex2_A.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}